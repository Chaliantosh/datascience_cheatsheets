{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adef4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Machine Learning is the science of teaching machines how to learn themselves. For e.g. smartphones detecting faces while\n",
    "taking photos or unlocking themselves; facebook, linkedin or any social media site recommending your friends and ads you \n",
    "might be interested in; amazon recommending you the products based on your browsing history; banks use machine learning to\n",
    "detect fraud transactions in real time.\n",
    "\n",
    "Types of Machine Learning:\n",
    "    1. Supervised Learning: \n",
    "        > Well defined goals\n",
    "        > Reverse Engineering\n",
    "        > e.g.: fraud/non-fraud transactions, inventory management\n",
    "        \n",
    "    2. Unsupervised Learning:\n",
    "        > Outcome is based only on inputs\n",
    "        > Outcome - typically clustering or segmentation\n",
    "        \n",
    "    3. Reinforcement Learning: \n",
    "        > Start state and end states are defined\n",
    "        > agent discovers the path & the relationships on its own\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf51d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Supervised machine learning techniques involve training a model to operate on a set of features and predict a label using a \n",
    "dataset that includes some already-known label values. The training process fits the features to the known labels to define \n",
    "a general function that can be applied to new features for which the labels are unknown, and predict them. You can think of \n",
    "this function like this, in which y represents the label we want to predict and x represents the features the model uses to \n",
    "predict it.\n",
    "\n",
    "y=f([x1,x2,x3,...])\n",
    "\n",
    "The goal of training the model is to find a function that performs some kind of calculation to the x values that produces \n",
    "the result y. We do this by applying a machine learning algorithm that tries to fit the x values to a calculation that \n",
    "produces y reasonably accurately for all of the cases in the training dataset.\n",
    "\n",
    "There are lots of machine learning algorithms for supervised learning, and they can be broadly divided into two types:\n",
    "\n",
    "Regression algorithms: Algorithms that predict a y value that is a numeric value, such as the price of a house or the number \n",
    "of sales transactions.\n",
    "Classification algorithms: Algorithms that predict to which category, or class, an observation belongs. The y value in a \n",
    "classification model is a vector of probability values between 0 and 1, one for each class, indicating the probability of \n",
    "the observation belonging to each class.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b258605",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Exploring Data: \n",
    "The first step in any machine learning project is to explore the data that you will use to train a model. The goal of this \n",
    "exploration is to try to understand the relationships between its attributes; in particular, any apparent correlation \n",
    "between the features and the label your model will try to predict. \n",
    "This may require some work \n",
    "1. Imputation Techniques: to detect and fix issues in the data (such as dealing with missing values, errors, or \n",
    "   outlier values), \n",
    "2. Feature Engineering: deriving new feature columns by transforming or combining existing features \n",
    "   (a process known as feature engineering), \n",
    "3. normalizing numeric features (values you can measure or count) so they're on a similar scale, \n",
    "4. encoding categorical features (values that represent discrete categories) as numeric indicators.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57a0453",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We could train a model using all of the data; but it's common practice in supervised learning to split the data into two \n",
    "subsets; a (typically larger) set with which to train the model, and a smaller \"hold-back\" set with which to validate the \n",
    "trained model. This enables us to evaluate how well the model performs when used with the validation dataset by comparing \n",
    "the predicted labels to the known labels. It's important to split the data randomly (rather than say, taking the first 70% \n",
    "of the data for training and keeping the rest for validation). This helps ensure that the two subsets of data are \n",
    "statistically comparable (so we validate the model with data that has a similar statistical distribution to the data on \n",
    "which it was trained).\n",
    "\n",
    "To randomly split the data, we'll use the train_test_split function in the scikit-learn library. This library is one of \n",
    "the most widely used machine learning packages for Python.\n",
    "\n",
    "Now we have the following four datasets:\n",
    "\n",
    "X_train: The feature values we'll use to train the model\n",
    "y_train: The corresponding labels we'll use to train the model\n",
    "X_test: The feature values we'll use to validate the model\n",
    "y_test: The corresponding labels we'll use to validate the model\n",
    "\n",
    "Now we're ready to train a model by fitting a suitable regression algorithm to the training data. We'll use a linear \n",
    "regression algorithm, a common starting point for regression that works by trying to find a linear relationship between the \n",
    "X values and the y label. The resulting model is a function that conceptually defines a line where every possible \n",
    "X and y value combination intersect.\n",
    "\n",
    "In Scikit-Learn, training algorithms are encapsulated in estimators, and in this case we'll use the LinearRegression \n",
    "estimator to train a linear regression model.\n",
    "\n",
    "Evaluate the Trained Model:\n",
    "Now that we've trained the model, we can use it to predict rental counts for the features we held back in our validation \n",
    "dataset. Then we can compare these predictions to the actual label values to evaluate how well (or not!) the model is \n",
    "working.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d99698",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Regression models are often chosen because they work with small data samples, are robust, easy to interpret, and a variety \n",
    "exist.\n",
    "\n",
    "Linear regression is the simplest form of regression, with no limit to the number of features used. Linear regression comes \n",
    "in many forms - often named by the number of features used and the shape of the curve that fits.\n",
    "    > Ordinary Least Squares\n",
    "    > Lasso\n",
    "    > Ridge\n",
    "\n",
    "Tree-based algorithms: Algorithms that build a decision tree to reach a prediction. Decision trees take a step-by-step \n",
    "approach to predicting a variable. If we think of our bicycle example, the decision tree may be first split examples \n",
    "between ones that are during Spring/Summer and Autumn/Winter, make a prediction based on the day of the week. \n",
    "Spring/Summer-Monday may have a bike rental rate of 100 per day, while Autumn/Winter-Monday may have a rental rate of \n",
    "20 per day.\n",
    "    > As an alternative to a linear model, there's a category of algorithms for machine learning that uses a tree-based \n",
    "      approach in which the features in the dataset are examined in a series of evaluations, each of which results in a \n",
    "      branch in a decision tree based on the feature value. At the end of each series of branches are leaf-nodes with \n",
    "      the predicted label value based on the feature values.\n",
    "\n",
    "Ensemble algorithms: Algorithms that combine the outputs of multiple base algorithms to improve generalizability. Ensemble \n",
    "algorithms construct not just one decision tree, but a large number of trees - allowing better predictions on more \n",
    "complex data. Ensemble algorithms, such as Random Forest, are widely used in machine learning and science due to their \n",
    "strong prediction abilities.\n",
    "    > Ensemble algorithms work by combining multiple base estimators to produce an optimal model, either by applying an \n",
    "      aggregate function to a collection of base models (sometimes referred to a bagging) or by building a sequence of \n",
    "      models that build on one another to improve predictive performance (referred to as boosting).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e5b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Classification is a form of machine learning in which you train a model to predict which category an item belongs to. For \n",
    "example, a health clinic might use diagnostic data such as a patient's height, weight, blood pressure, blood-glucose level \n",
    "to predict whether or not the patient is diabetic.\n",
    "\n",
    "Categorical data has distinct 'classes', rather than numeric values. Some kinds of data can be either numeric \n",
    "or categorical: the time to run a race could be a time in seconds, or we could split times into classes of ‘fast’, ‘medium’ \n",
    "and ‘slow’ - categorical. While other kinds of data can only be categorical, such as a type of shape - ‘circle’, \n",
    "‘triangle’, or ‘square’.\n",
    "\n",
    "Classification is a form of supervised machine learning in which you train a model to use the features (the x values in our \n",
    "function) to predict a label (y) that calculates the probability of the observed case belonging to each of a number of \n",
    "possible classes, and predicting an appropriate label. The simplest form of classification is binary classification, in \n",
    "which the label is 0 or 1, representing one of two classes; for example, \"True\" or \"False\"; \"Internal\" or \"External\"; \n",
    "\"Profitable\" or \"Non-Profitable\"; and so on.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5dc469",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Logistic Regression, which (despite its name) is a well-established algorithm for classification. In addition to the \n",
    "training features and labels, we'll need to set a regularization parameter. This is used to counteract any bias in the \n",
    "sample, and help the model generalize well by avoiding overfitting the model to the training data.\n",
    "\n",
    "Note: Parameters for machine learning algorithms are generally referred to as hyperparameters (to a data scientist, \n",
    "parameters are values in the data itself - hyperparameters are defined externally from the data!)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aca850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The classification report includes the following metrics for each class  (0 and 1):\n",
    "Precision: Of the predictions the model made for this class, what proportion were correct?\n",
    "Recall: Out of all of the instances of this class in the test dataset, how many did the model identify?\n",
    "F1-Score: An average metric that takes both precision and recall into account.\n",
    "Support: How many instances of this class are there in the test dataset?\n",
    "\n",
    "Because this is a binary classification problem, the 1 class is considered positive and its precision and recall are \n",
    "particularly interesting - these in effect answer the questions:\n",
    "> Of all the patients the model predicted are diabetic, how many are actually diabetic?\n",
    "> Of all the patients that are actually diabetic, how many did the model identify?\n",
    "\n",
    "The precision and recall metrics are derived from four possible prediction outcomes:\n",
    "> True Positives: The predicted label and the actual label are both 1.\n",
    "> False Positives: The predicted label is 1, but the actual label is 0.\n",
    "> False Negatives: The predicted label is 0, but the actual label is 1.\n",
    "> True Negatives: The predicted label and the actual label are both 0.\n",
    "\n",
    "These metrics are generally tabulated for the test set and shown together as a confusion matrix, which takes the following \n",
    "form:\n",
    "\n",
    "TN\tFP\n",
    "FN\tTP\n",
    "\n",
    "Note that the correct (true) predictions form a diagonal line from top left to bottom right - these figures should be \n",
    "significantly higher than the false predictions if the model is any good.\n",
    "\n",
    "Statistical machine learning algorithms, like logistic regression, are based on probability; so what actually gets predicted\n",
    "by a binary classifier is the probability that the label is true (P(y)) and the probability that the label is false \n",
    "(1 - P(y)). A threshold value of 0.5 is used to decide whether the predicted label is a 1 (P(y) > 0.5) or a 0 (P(y) <= 0.5).\n",
    "You can use the predict_proba method to see the probability pairs for each case.\n",
    "\n",
    "The decision to score a prediction as a 1 or a 0 depends on the threshold to which the predicted probabilities are compared.\n",
    "If we were to change the threshold, it would affect the predictions; and therefore change the metrics in the confusion \n",
    "matrix. A common way to evaluate a classifier is to examine the true positive rate (which is another name for recall) and \n",
    "the false positive rate for a range of possible thresholds. These rates are then plotted against all possible thresholds to \n",
    "form a chart known as a received operator characteristic (ROC) chart. \n",
    "The ROC chart shows the curve of the true and false positive rates for different threshold values between 0 and 1. \n",
    "A perfect classifier would have a curve that goes straight up the left side and straight across the top. The diagonal line \n",
    "across the chart represents the probability of predicting correctly with a 50/50 random prediction; so you obviously want \n",
    "the curve to be higher than that (or your model is no better than simply guessing!).\n",
    "\n",
    "The area under the curve (AUC) is a value between 0 and 1 that quantifies the overall performance of the model. The closer \n",
    "to 1 this value is, the better the model. \n",
    "\n",
    "In this case, the ROC curve and its AUC indicate that the model performs better than a random guess which is not bad \n",
    "considering we performed very little preprocessing of the data.\n",
    "\n",
    "In practice, it's common to perform some preprocessing of the data to make it easier for the algorithm to fit a model to it.\n",
    "There's a huge range of preprocessing transformations you can perform to get your data ready for modeling, but we'll limit \n",
    "ourselves to a few common techniques:\n",
    "> Scaling numeric features so they're on the same scale. This prevents features with large values from producing \n",
    "  coefficients that disproportionately affect the predictions.\n",
    "> Encoding categorical variables. For example, by using a one hot encoding technique you can create individual binary \n",
    "  (true/false) features for each possible category value.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e682da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Previously we used a logistic regression algorithm, which is a linear algorithm. There are many kinds of classification \n",
    "algorithm we could try, including:\n",
    "> Support Vector Machine algorithms: Algorithms that define a hyperplane that separates classes.\n",
    "> Tree-based algorithms: Algorithms that build a decision tree to reach a prediction\n",
    "> Ensemble algorithms: Algorithms that combine the outputs of multiple base algorithms to improve generalizability.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bd35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From these core values, you can calculate a range of other metrics that can help you evaluate the performance of the model. \n",
    "For example:\n",
    "\n",
    "Accuracy: (TP+TN)/(TP+TN+FP+FN) - out all of the predictions, how many were correct?\n",
    "Recall: TP/(TP+FN) - of all the cases that are positive, how many did the model identify?\n",
    "Precision: TP/(TP+FP) - of all the cases that the model predicted to be positive, how many actually are positive?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253bfe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Multiclass classification can be thought of as a combination of multiple binary classifiers. There are two ways in which you\n",
    "approach the problem:\n",
    "\n",
    "One vs Rest (OVR), in which a classifier is created for each possible class value, with a positive outcome for cases where \n",
    "the prediction is this class, and negative predictions for cases where the prediction is any other class. \n",
    "For example, a classification problem with four possible shape classes (square, circle, triangle, hexagon) would require \n",
    "four classifiers that predict:\n",
    "> square or not\n",
    "> circle or not\n",
    "> triangle or not\n",
    "> hexagon or not\n",
    "One vs One (OVO), in which a classifier for each possible pair of classes is created. The classification problem with four \n",
    "shape classes would require the following binary classifiers:\n",
    "> square or circle\n",
    "> square or triangle\n",
    "> square or hexagon\n",
    "> circle or triangle\n",
    "> circle or hexagon\n",
    "> triangle or hexagon \n",
    "\n",
    "In both approaches, the overall model must take into account all of these predictions to determine which single category the\n",
    "item belongs to. Fortunately, in most machine learning frameworks, including scikit-learn, implementing a multiclass \n",
    "classification model is not significantly more complex than binary classification - and in most cases, the estimators used \n",
    "for binary classification implicitly support multiclass classification by abstracting an OVR algorithm, an OVO algorithm, or\n",
    "by allowing a choice of either.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
